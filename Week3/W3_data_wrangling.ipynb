{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "homeless-heart",
   "metadata": {},
   "source": [
    "# Learning goals\n",
    "After this week's lesson you should be able to:\n",
    "- Refresher on data structure (DF vs Series vs List vs Array)\n",
    "- Checking a columns data types and converting types\n",
    "- Rename a (geo)dataframe column \n",
    "- parsing dates\n",
    "- slicing strings\n",
    "- handling missing data. \n",
    "    - filtering out missing data\n",
    "    - replacing missing data with the mean\n",
    "- Merging \n",
    "- More on groupby-and-summarize\n",
    "- (Defining and using a function)\n",
    "- (iterating over rows)\n",
    "- (applying a function)\n",
    "\n",
    "This week's lessons are adapted from:\n",
    "- [PPD599: Advanced Urban Analytics](https://github.com/gboeing/ppd599/tree/main/syllabus)\n",
    "- [Geo-Python Lesson 5](https://geo-python-site.readthedocs.io/en/latest/notebooks/L5/processing-data-with-pandas.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cacc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to start importing the libraries we need\n",
    "# all in one cell. \n",
    "# It is a good practice to keep all the imports in one cell so that\n",
    "# we can easily see what libraries we are using in the notebook.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a30b2",
   "metadata": {},
   "source": [
    "# 0. Refresher\n",
    "Before we move on, let's go over the different types of data structures we've encountered so far. We are going to cover: \n",
    "- Pandas DataFrames\n",
    "- Pandas Series\n",
    "- Lists\n",
    "- Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de530ee7",
   "metadata": {},
   "source": [
    "## 0.1 Pandas: Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = pd.read_csv('msa_by_pop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a103e6",
   "metadata": {},
   "source": [
    "What makes `msa` a dataframe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d63d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a09f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the type() function to see what type of object we have\n",
    "type(msa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d22cea",
   "metadata": {},
   "source": [
    "Now let's select just the `population_2020` column from `msa`. What makes the following a pandas Series? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4d601",
   "metadata": {},
   "source": [
    "## 0.2 Pandas: Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07751a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa['population_2020'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(msa['population_2020'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb72d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.Series([19768458, 12997353, 9509934, 7759615, 7206841],    \n",
    "            index=['NYC', 'LA', 'Chicago', 'Dallas', 'Houston'])\n",
    "population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab3d55",
   "metadata": {},
   "source": [
    "## 0.3 Python data structures: Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2dd56e",
   "metadata": {},
   "source": [
    "Now, let's just select the values from `population` as a **list**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a list of numbers\n",
    "## A list is a collection of objects of any type.\n",
    "## It is created by putting the objects in square brackets\n",
    "\n",
    "list1 = [19768458, 12997353, 9509934, 7759615, 7206841]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08796572",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c685edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae10bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is also a list\n",
    "## But instead of being a list of numbers, it is a list of strings\n",
    "\n",
    "list2 = ['NYC', 'LA', 'Chicago', 'Dallas', 'Houston']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791d10f",
   "metadata": {},
   "source": [
    "## 0.4 Numpy: Arrays\n",
    "\n",
    "We are not going to cover numpy directly in the class. But there is another list-like data structure used by the `numpy` library called an **array**. \n",
    "\n",
    "Though we are inputting a list above to create a pandas Series, pandas will turn this list into a **numpy array**. All pandas series are basically just generalized version of numpy arrays. \n",
    "\n",
    "An array is a collection of objects of the same type. It is created by putting the objects in square brackets and using the `np.array()` function. A numpy array is most used for numerical calculations such as finding the mean, min, sum of a set of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303144ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1_as_array = np.array(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1_as_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca61703",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1_as_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d8d4e",
   "metadata": {},
   "source": [
    "# 1. Data cleaning\n",
    "As you might have already seen, when we work with data, it is not always in a shape that we can use it, sometimes column names are misspelled, there are missing values. You may also have noticed that often we can extract information from columns that might make them easier to work with. All these steps can be considered part of a data cleaning or data wrangling process, where we get the dataset ready to be used more effectively for our analysis purposes. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11ea26",
   "metadata": {},
   "source": [
    "## 1.1 Getting the data\n",
    "Let's say we want to compare the relationship between the **total number of students in a general ed public school** to the **money spent on new school construction and improvements in that school**. \n",
    "\n",
    "### School Construction Authority\n",
    "\n",
    "First, go ahead and download the [Active Projects Under Construction](https://data.cityofnewyork.us/Housing-Development/Active-Projects-Under-Construction/8586-3zfm) dataset as a CSV and save it down to the folder where this notebook is. This is a dataset of new school projects (Capacity) and Capital Improvement Projects (CIP) currently under Construction, created by the School Construction Authority. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc074468",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we are going to read a csv directly from the web\n",
    "## We are going to use the read_csv() function from the pandas library\n",
    "## \n",
    "\n",
    "projects_under_const = pd.read_csv('Active_Projects_Under_Construction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f92c68",
   "metadata": {},
   "source": [
    "Also, go ahead and download the data dictionary `SCA Active Projects in Construction Data Dictionary.xlsx`. Data dictionaries often have explanations for what each column name represents and other useful information about the data. \n",
    "\n",
    "\n",
    "If you open up the data dictionary, does it correspond to the \"Columns in this Dataset\" section in the NYC OpenData's page on this dataset? No, right? We have to be careful about these inconsistencies, even in official portals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca503a",
   "metadata": {},
   "source": [
    "Taking a look at the first five rows we can already see there is a lot of missing data in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817c301",
   "metadata": {},
   "source": [
    "### Class size dataset\n",
    "Also download the [2021 - 2022 Average Class Size by School](https://data.cityofnewyork.us/Education/2021-2022-Average-Class-Size-by-School/sgr7-hhwp) dataset, along with it's attachments. (Here, only `2021-2022 Average Class Size By School DD.xlsx` is the data dictoinary, the other is the dataset as an excel spreadsheet). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size = pd.read_csv('2021_-_2022_Average_Class_Size_by_School.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d744838",
   "metadata": {},
   "source": [
    "Here, most of the columns make sense to me. From the data dictionary, I can see that Program Type is coded as follows:\n",
    "\n",
    "- General Education (Gen Ed), \n",
    "- Integrated Co-Teaching (ICT), \n",
    "- Gifted and Talented (G&T), \n",
    "- Self-Contained (SC)\n",
    "- Accelerated (Acc)\"\n",
    "\n",
    "\n",
    "What does not make sense is the `Minimum Class Size` column, which seems to be the same as the maximum class size column in some cases. Therefore, I'll likely not use this column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c30f5eb",
   "metadata": {},
   "source": [
    "## 1.2 Assessing Data Types\n",
    "One of the next things we'll check is the data type for each column to make sure that they are in the right format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac3b7b0",
   "metadata": {},
   "source": [
    "I would not necessarily change the data types for all columns (especially when there are a lot), but just the ones that you might potentially need. Here, `Maximum Class Size` is an `object` format (I'm going to ignore `Minimum Class Size` for now), likely because the size is sometimes input as `<INT` and sometimes `INT`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d6d0b",
   "metadata": {},
   "source": [
    "## 1.3 Removing strings\n",
    "\n",
    "In order to change the data type of the min and max class size to an `int` we have to clean up those columns a little bit. \n",
    "\n",
    "The function `.replace('str_to_be_replaced','str_to_replace_with)` will take `str_to_be_replaced` and replace it with `str_to_replace_with`. Here, I'm setting `<` to be replaced by nothing which is expressed as an empty string `\"\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38621987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, I'm going to check that the function worked as expected first\n",
    "# here .str is a method that is applied to a string\n",
    "# it is a vectorized string method\n",
    "class_size['Maximum Class Size'].str.replace('<', \"\")\n",
    "\n",
    "# (Vectorization is the process of converting an algorithm from operating on a single value at a time to operating on a set of values at one time\n",
    "# but it's not super important for us to know what this is right now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5377db37",
   "metadata": {},
   "source": [
    "Now lets assign the result to a new column and why not rename the column to something in snake case. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['max_class_size_clean'] = class_size['Maximum Class Size'].str.replace('<', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc6127a",
   "metadata": {},
   "source": [
    "Now let's see if we can turn the column `min_class_size_clean` into an `integer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['max_class_size_clean'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b1aaa",
   "metadata": {},
   "source": [
    "Oops, I guess we also have to replace the greater than `>`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c476ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['max_class_size_clean'] = class_size['max_class_size_clean'].str.replace('>', \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3acbb",
   "metadata": {},
   "source": [
    "## 1.4 Changing data types\n",
    "Now let's try to change the data type for `max_class_size_clean`. \n",
    "\n",
    "`.astype()` changes your column types for a particular column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bad4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What I've done here is replace the old `max_class_size_clean` column with \n",
    "## a version of it that is an int\n",
    "class_size['max_class_size_clean'] = class_size['max_class_size_clean'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add1dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that `int` from above defaults to 64 bit integers. \n",
    "class_size['max_class_size_clean'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd50d8",
   "metadata": {},
   "source": [
    "## 1.5 Slicing strings\n",
    "\n",
    "### 1.5.1\n",
    "The `projects_under_const` has a `Data as Of` column, which gives us some temporal variation in when, at least the data was added to the table. It could be useful, for instance, if we think that `Data as Of` is a rough proxy for when the project was funded or approved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58400bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that NaN means \"Not a Number\".\n",
    "# In other words, it is a missing value\n",
    "projects_under_const['Data As Of'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075f8efd",
   "metadata": {},
   "source": [
    "Let's say we want to extract year from these dates. We have another string-related function we can apply to all of our values under `Data As Of`. \n",
    "\n",
    "`.split()` splits strings around given separator/delimiter to create a list of strings. \n",
    "\n",
    "Here, we will use `/` as our separator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const['Data As Of'].str.split('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be40d0",
   "metadata": {},
   "source": [
    "Now we just have to get the last value (where it exists) and create a new column with the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [-1] is a way to access the last element of a list\n",
    "projects_under_const['data_year'] = projects_under_const['Data As Of'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0075330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that when there was an NaN, the split function returned a NaN\n",
    "projects_under_const['data_year'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c4676b",
   "metadata": {},
   "source": [
    "### 1.5.2\n",
    "We will eventually be comparing school attendance characteristics to money allocated through **merging along a common column name** at the **school level**.\n",
    "\n",
    "What are out options here? Let's take  look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f247b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f164843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9220b8",
   "metadata": {},
   "source": [
    "Even though there is a **School Name** column in both datasets, the format seems to be quite different. \n",
    "- For the `projects_under_const` dataset, the school names are all over the place. Some are the name and borough separated by a `-`, some also include an `@` followed by a rough locationn. \n",
    "- For the `class_size` df, the school names are consistent, but we can see that it might be a pain to match the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const['School Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['School Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46fb71d",
   "metadata": {},
   "source": [
    "Instead, I noticed that there's a `Building ID` column in the `projects_under_constr` DF (dataframe, for short) that, though is described unhelpfully as \"ID of the Building\" in the documentation, looks to be similar to the `DBN` from `class_size` DF. In fact, when I look at what `DBN` is in the class size documentation, it says that this column \"Denotes cocatenation[sic] of district, borough and three digit school number.\"\n",
    "\n",
    "I'm going to guess here that if I extract the \"borough and three digit school number\" part of `DBN`, this will match my `Building ID` column. \n",
    "\n",
    "Thankfully, it seems like there is a fixed number of characters I need extract from `DBN`: \n",
    "- Borough = 1\n",
    "- School number = 3\n",
    "\n",
    "In total, I will need the last 4 characters from `DBN`. We'll do this again with a string splice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am going to use the str method to get the last 4 characters of the DBN\n",
    "# within the square brackets, I am taking everything fourth from the end onwards\n",
    "# That's what -4 means\n",
    "\n",
    "class_size['DBN'].str[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35725fc9",
   "metadata": {},
   "source": [
    "Quick review of selecting ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa57e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a little strange because backwards counting starts at -1\n",
    "\n",
    "class_size['DBN'].str[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0cedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, 4: means that I want to start at the fifth character \n",
    "## because python starts counting at 0 for forward counting\n",
    "class_size['DBN'].str[4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "## And if I wanted to select a slice of the string in the middle\n",
    "## I can do the following\n",
    "class_size['DBN'].str[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80fb48f",
   "metadata": {},
   "source": [
    "Back to our exericse, let's assign our slice to a new colunn called `bid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['bid'] = class_size['DBN'].str[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3679254",
   "metadata": {},
   "source": [
    "## 1.6 Handling missing data\n",
    "Now, let's say that our analysis depends knowing the year the data was created. There are a few ways of handling missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b828f",
   "metadata": {},
   "source": [
    "### 1.6.1 Removing rows \n",
    "We can remove those rows with data missing from a column that we are planning to use in our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to use the isna() function to check if the data_year column has a NaN\n",
    "# isna() returns a boolean (True or False) for each row\n",
    "# and we are going to use that boolean to filter the dataframe. \n",
    "# We are going to keep only the rows where the data_year column is not a NaN\n",
    "\n",
    "projects_under_const_new = projects_under_const[projects_under_const['data_year'].isna()==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc5697",
   "metadata": {},
   "source": [
    "### 1.6.2 Replacing missing data\n",
    "We can also replace the missing data with certain values: \n",
    "- We can replace the data with the mean of the non-NaN column values, for numerical values. (For instance, if our columns were something like \"adult heights\", then replacing the NaN with the mean values in the columns would allow us to leave the sample mean unchanged, which might be good for regression purposes). \n",
    "- We can also replace with the median (if you think there are outliers in the sample that might be skewing the mean)\n",
    "- Replacing with the mode (most frequent value) would make more sense if we think that there's some default value \n",
    "\n",
    "**What would you do here?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets the mode of the data_year column\n",
    "mode_year = projects_under_const['data_year'].mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fills the NaNs with the mode using the fillna() function\n",
    "# fillna() is a method that fills in missing values with a value of your choice\n",
    "projects_under_const['data_year'].fillna(mode_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write over the old data_year column with the new one\n",
    "projects_under_const['data_year'] = projects_under_const['data_year'].fillna(mode_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49012f5e",
   "metadata": {},
   "source": [
    "## Q1. In-Class Exercise 1 (5 pts)\n",
    "In the end, was it the best idea to replace the NaN data in `data_year`? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18228c3a",
   "metadata": {},
   "source": [
    "## 1.7 Aggregating data: A review of groupby-and-summarize\n",
    "Last week, we introduced the \"groupby-and-summarize\" operation that is very common in pandas. It's common because we often want to aggregate data by some category. For example, we might want to know the total amount of construction money allocated by school. Or we might want to know the total number of students in each school.\n",
    "\n",
    "For the projects under construction, let's group by the `Building ID`, which we had a hunch was the same as the `DBN` (Borough and School ID) to get the: \n",
    "- Total construction award amount per school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d265c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remember that .sum() will only sum the numeric columns\n",
    "projects_under_const.groupby('Building ID').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b182f9",
   "metadata": {},
   "source": [
    "Most of these columns are gibberish after we sum (for ex: we don't need a sum of latitudes and longitudes by school). Let's just select the columns we want to use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remeber the brackets after a DF allow you to select columns\n",
    "projects_under_const.groupby('Building ID').sum()['Construction Award']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583d7df",
   "metadata": {},
   "source": [
    "Let's assign this to a new variable name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const_agg = projects_under_const.groupby('Building ID').sum()['Construction Award']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6f1a3",
   "metadata": {},
   "source": [
    "Here you can see that the result is a **pandas Series**. To make this easier to work with during the merge, let's transform this into a pandas DF. \n",
    "\n",
    "I'm going to use a function call `.reset_index()` as a trick to do this. `.reset_index()` is a method that resets the index of a dataframe to a column of your choice. The default is to reset the index to a column of sequential numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how Building ID, which was the index before, is now a column. \n",
    "# and the index is i just 0,...,1180\n",
    "\n",
    "projects_under_const_agg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992be19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const_agg = projects_under_const_agg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835da52b",
   "metadata": {},
   "source": [
    "Let's do something similar with the `class_size` df. As we can see from the below, our data is likely one row per grade and program. We want to aggregate this to the school level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42dff8f",
   "metadata": {},
   "source": [
    "I'm first going to filter my DF since I just want 'Gen Ed' in order not to skew the representative class size by special programs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d0be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .unique() returns a list of all the unique values in a column\n",
    "class_size['Program Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to use the == operator to check if the value in the Program Type column is equal to 'Gen Ed'\n",
    "# Then we'll set this filtered dataframe to a new variable\n",
    "# and use that new dataframe from now on. \n",
    "class_size_new = class_size[class_size['Program Type']=='Gen Ed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db69ba",
   "metadata": {},
   "source": [
    "Now, to get the total number of students in each school, I'll have to: \n",
    "- Multiply `Number of Classes` and `Number of Students` (let's assume this is per class)\n",
    "- Sum the total number of students across all classes in a school. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new['total_students_in_grade'] = class_size_new['Number of Students'] * class_size_new['Number of Classes']\n",
    "# Yes, ignore the SettingWithCopyWarning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b52442c",
   "metadata": {},
   "source": [
    "Now let's groupby `bid` and sum all the grades within each school. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d43db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new.groupby('bid').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50765542",
   "metadata": {},
   "source": [
    "Again, we'll just need the `total_students_in_grade` column here. And I'm going to do the `reset_index()` trick again. This time, I'm going to string all these steps together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a8343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas reads this code from left to right and will apply each function on the right to the everything on the left\n",
    "# So, first we are going to group by bid\n",
    "# Then we are going to sum each group\n",
    "# Then from the entire summed dataframe, we are going to select the total_students_in_grade column\n",
    "# Selecting that series, we are going to reset the index to create our new dataframe. .\n",
    "\n",
    "class_size_new_agg = class_size_new.groupby('bid').sum()['total_students_in_grade'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed44186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b6ef1",
   "metadata": {},
   "source": [
    "Finally, we get to do our merge. We are going to merge \n",
    "- `projects_under_cont_agg`\n",
    "- `class_size_new_agg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdad3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new_agg.merge(projects_under_const_agg,left_on='bid',right_on='Building ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba06c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = class_size_new_agg.merge(projects_under_const_agg,left_on='bid',right_on='Building ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b39cf",
   "metadata": {},
   "source": [
    "Ok, finally, to get to our answer, we're going to apply the `.corr()` function to our dataframe. The [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) tells us that this function computes pairwise correlation of columns, excluding NA/null values.\n",
    "\n",
    "The default method is a 'Pearson' correlation, with all methods being: \n",
    "- pearson : standard correlation coefficient\n",
    "- kendall : Kendall Tau correlation coefficient\n",
    "- spearman : Spearman rank correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yikes, 0.079 correlation. I guess I assumed wrong that there would be an strong correlation between the number of students in a school and the amount of money spent on construction.\n",
    "merged_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4d00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a rank correlation instead of a linear correlation hasn't improved the correlation much.\n",
    "# (Don't worry about what this is right now.)\n",
    "merged_df.corr(method = 'spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5df030",
   "metadata": {},
   "source": [
    "This was a long lecture, no more exercises!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc571d7ca67236538d190807671ab3198970b7d67f23d825ad141ff90f68066a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
