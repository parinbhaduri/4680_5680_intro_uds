{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "homeless-heart",
   "metadata": {},
   "source": [
    "# Learning goals\n",
    "After this week's lesson you should be able to:\n",
    "- Perform an overlay analysis\n",
    "- Reclassify data\n",
    "- Perform a spatial join (Refresher)\n",
    "\n",
    "This week's lessons are adapted from:\n",
    "- [Automating GIS Processes Lesson 3](https://autogis-site.readthedocs.io/en/latest/lessons/lesson-3/overview.html)\n",
    "- [Automating GIS Processes Lesson 4](https://autogis-site.readthedocs.io/en/latest/lessons/lesson-4/overview.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cacc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to start importing the libraries we need\n",
    "# all in one cell. \n",
    "# It is a good practice to keep all the imports in one cell so that\n",
    "# we can easily see what libraries we are using in the notebook.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd3a30b2",
   "metadata": {},
   "source": [
    "# 1. Overlay Analysis\n",
    "Overlay analyses are GIS operations in which two or more vector layers are combined to produce new geometries. Typical overlay operations include union, intersection, and difference - named after the result of the combination of two layers.\n",
    "\n",
    "</figure>\n",
    "<img src=\"https://autogis-site.readthedocs.io/en/latest/_images/overlay-operations_700x200px.svg\" alt=\"drawing\" width=\"700\" style=\"display: block; margin: 0 auto\"/>\n",
    "</figure>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de530ee7",
   "metadata": {},
   "source": [
    "## 1.1 Loading data\n",
    "Let's say we wanted to study which [neighborhoods](https://data.cityofnewyork.us/City-Government/NTA-map/d3qk-pfyz) in NYC are more vulnerable to flooding. Here, we will measure vulnerability as the areal coverage of the neighborhood by the [NYC Stormwater Flood Map](https://data.cityofnewyork.us/City-Government/NYC-Stormwater-Flood-Map-Moderate-Flood-with-2050-/5rzh-cyqd). \n",
    "\n",
    "Let's download two datasets and put it into our current folder: \n",
    "- The [Neighborhood Tabulation Areas](https://data.cityofnewyork.us/City-Government/NTA-map/d3qk-pfyz) (make sure to download the shapefile)\n",
    "- [NYC Stormwater Flood Map - Moderate Flood with 2050 Sea Level Rise](https://data.cityofnewyork.us/City-Government/NYC-Stormwater-Flood-Map-Moderate-Flood-with-2050-/5rzh-cyqd) There is a zip file in on this page and you will have to unzip to read a `.gdb` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed0e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta = gpd.read_file('NTA map.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I'm sorry this file is a pain \n",
    "## It is a .gdb file, which is a geodatabase file in ArcGIS\n",
    "## It only has one layer, so we can just read it in with layer=0\n",
    "## We can also use the driver='FileGDB' to tell geopandas that it is a geodatabase file\n",
    "## Though Geopandas will infer the file format from the file extension, so we don't need to specify the driver \n",
    "\n",
    "\n",
    "\n",
    "flood_2050 = gpd.read_file(\"NYC_Stormwater_Flood_Map_-_Moderate_Flood_with_2050_Sea_Level_Rise/NYC Stormwater Flood Map - Moderate Flood with 2050 Sea Level Rise.gdb\",\n",
    "                        driver='FileGDB', \n",
    "                        layer=0)\n",
    "                        \n",
    "# And this file name is terrible. \n",
    "# Ok enough griping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96122452",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_2050.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59f99d9e",
   "metadata": {},
   "source": [
    "This is unusual. There are only three rows in the dataset! Judging by the `Flooding_Category` column an the fact that each entry in the `geometry` column is a **MULTIPOLYGON** (we're going to ignore the Z part. This is actually a 3D polygon, but we won't work with the third dimension in this example.)\n",
    "\n",
    "Looking, in the data dictionary for the flood data, which should be the `.xlsx` file in the unzipped folder we can see that these are the following categories definitions: \n",
    "- 1 - Nuisance Flooding (greater or equal to 4 in. and less than 1 ft.)\n",
    "- 2 - Deep and Contiguous Flooding (1 ft. and greater)\n",
    "- 3 - Future High Tides 2050\n",
    "\n",
    "I'm going to make a quick categorical plot to get a sense of what the data may look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e139e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_2050.plot('Flooding_Category',\n",
    "                figsize=(10,10),\n",
    "                legend=True,\n",
    "                categorical=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "893693e3",
   "metadata": {},
   "source": [
    "For now, let's just use **Category 1 \"Nuisance Flooding\"** to simplify this calculation. I'm going to create a new gdf called `flood_2020_cat1` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae65b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_2050_cat1 = flood_2050[flood_2050['Flooding_Category'] == 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd6c4981",
   "metadata": {},
   "source": [
    "## 1.2 `.overlay()`\n",
    "We'll want to estimate the **percentage of the neighborhood at risk of all categories of flooding**. The first step is to do the following: \n",
    "1. Check the CRS between our two layers to make sure they are the same. \n",
    "2. Find the **Intersection** of geometries, using the `.overlay()`, function between the neighborhoods and the flood zones: That is we'll want to find the shapes that overlap between the neighborhood and each flood zone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96853894",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd803690",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_2050_cat1.crs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d9ab4c4",
   "metadata": {},
   "source": [
    "Looks like they are different: \n",
    "- `nta` is **EPSG:4326**\n",
    "- `flood_2050` is **EPSG:2263**\n",
    "\n",
    "Notice that EPSG:2263 is in **feet**. Again, whenever we want to estimate areas, volumes, or lengths, we'll want to do this in a CRS in a unit that we can understand. (Areas in degrees doesn't make too much sense.) \n",
    "\n",
    "For now, let's convert the `nta` to **EPSG:2263** to have our measurements in **feet**. I'm going to create a new gdf `nta_2223`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018aacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_2263 = nta.to_crs(flood_2050_cat1.crs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c392382",
   "metadata": {},
   "source": [
    "Finally, I want to create this overlay and assign it to a new gdf called `nta_2263_overlay_flood`. Note: This may take little bit of time as the `.overlay()` function is calculating all possible matches. Between geometries in `nta_2263` and `flood_2050_cat1`. (It took about 45 seconds on my computer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895ed244",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_2263_overlay_flood = gpd.overlay(nta_2263,flood_2050_cat1,how='intersection')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fa85f5f",
   "metadata": {},
   "source": [
    "## Q.1 Groupby-and-summarize (5 pts)\n",
    "How many rows for each neighborhood are there? `nta_2263_overlay_flood`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb98ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88fd6b31",
   "metadata": {},
   "source": [
    "Let's take a look at what resulted. We can see here that we have columns from both the neighborhoods and flood gdfs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_2263_overlay_flood.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I'm just going to select one neighborhood and see what this overlay looks like\n",
    "fig1,ax1 = plt.subplots(1,1,figsize=(10,10))\n",
    "\n",
    "## Plotting the neighborhood BK43\n",
    "nta_2263[nta_2263['ntacode']=='BK43'].plot(ax=ax1)\n",
    "\n",
    "## Plotting the flood zone intersecting with the neighborhood\n",
    "nta_2263_overlay_flood[nta_2263_overlay_flood['ntacode']=='BK43'].plot(ax=ax1,color='red')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9330faa9",
   "metadata": {},
   "source": [
    "## 1.3 Find area percentage\n",
    "For all neighborhoods, I'll want to find: \n",
    "$$\n",
    "\\% floodzone_{n} =\\frac{A_{fn}}{A_{n}}\n",
    "$$\n",
    "\n",
    "where $n$ is a neighborhood, $A_{fn}$ is the area of the flood zone that intersects with that neighborhood $n$ and $A_n$ is the area of the neighorhood.\n",
    "\n",
    "(Yes we can write mathematical notation in Markdown using LaTex! No, I won't make you do it if you aren't already familiar with LaTex.)\n",
    "\n",
    "To do this, we'll need: \n",
    "- $A_{fn}$ \n",
    "- $A_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d2053",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_2263_overlay_flood['area_flood'] = nta_2263_overlay_flood.area\n",
    "nta_2263['area_neighb'] = nta_2263.area"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85c8736b",
   "metadata": {},
   "source": [
    "## 1.4 Merge\n",
    "I'm now going merge my `nta_2263_overlay_flood` gdf with the `nta_2263` because I want to divide `area_flood` and `area_neighb`. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Again I'm just going to select the two columns I need, the neighborhood code (to perform the merge) and the area of the flood zone (to calculate the percentage of the neighborhood that is flooded)\n",
    "## I'm going to use a left join, so that I keep all the neighborhoods in the original dataset, \n",
    "## even if they don't intersect with the flood zone dataset\n",
    "\n",
    "nta_2263_merged = nta_2263.merge(nta_2263_overlay_flood[['ntacode','area_flood']],on='ntacode',how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9e9801b",
   "metadata": {},
   "source": [
    "Super! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c487cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_2263_merged.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf71a27e",
   "metadata": {},
   "source": [
    "## 1.5 Calculate percentage\n",
    "Lastly, we'll just have to calculate the percentage of the flood zone in each neighborhood. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8064a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_2263_merged['perc_flood'] = nta_2263_merged['area_flood']/nta_2263_merged['area_neighb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90628c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_2263_merged.plot(column='perc_flood', \n",
    "                        legend=True,\n",
    "                        figsize=(10,10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4a10bd1",
   "metadata": {},
   "source": [
    "## Q.2 - Topical Knowledge (5 pts)\n",
    "Here we used flood zone coverage in a neighborhood as proxy for flood. Why might this be an inexact estimate of flood risk? Propose and describe at least three factors we may not have considered in this analysis. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6958f3e",
   "metadata": {},
   "source": [
    "## 1.5 Re-classifying data\n",
    "Now, instead of using the `perc_flood` column, I want to translate the values in this column into categories that might be more meaningful to a general audience. \n",
    "\n",
    "- We might consider binning our values into \"Low\", \"Average\", and \"High\" risk categories. How to determine these? The best approach is have some topical knowledge. For instance, we might read from research reports, look at previous flooding records of these neigbhohoods, etc, to acquire an understanding of how to bin values. \n",
    "- A less informed strategy could be to categorize by the distribution of our data. \n",
    "\n",
    "We'll take a the less informed strategy here for the sake of time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37231d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remember that the describe function gives us some basic statistics about the data\n",
    "nta_2263_merged['perc_flood'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e869e9f1",
   "metadata": {},
   "source": [
    "From the above, we'll use the following criteria: \n",
    "- Less than 25th percentile = Low\n",
    "- 25-75th percentile = Average\n",
    "- 75th percentile or higher = High\n",
    "\n",
    "To express this in code. We will: \n",
    "- Create a new empty column \n",
    "- Filter our gdf based on each criteria\n",
    "- Assign a different category to each criteria. \n",
    "\n",
    "### 1.5.1\n",
    "First, let's create an empty string column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that \"\" is an empty string\n",
    "nta_2263_merged['risk_categories'] =\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b65036b6",
   "metadata": {},
   "source": [
    "See that we have a column called `risk_categories` that contains empty strings (note: not the same as `NaN`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f90b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_2263_merged.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b95ea6c6",
   "metadata": {},
   "source": [
    "### 1.5.2 \n",
    "Now we'll filter for each criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78428da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I'm going to use .loc instead of the square bracket method to select the rows and columns I want to edit\n",
    "## Remember that .loc is used to select rows and columns by label\n",
    "\n",
    "## So I simultaneously select my filtering criteria for rows and the column I want to edit. \n",
    "## 0.004067 is the 25th percentile of the data\n",
    "nta_2263_merged.loc[nta_2263_merged['perc_flood']<0.004067,'risk_categories'] = 'low'\n",
    "\n",
    "## A lot of things are happening here: \n",
    "## 1. We're filtering for two conditions: Both >=25% and <=75% \n",
    "## 2. Because I have multiple conditions, I need to use the & operator to combine them \n",
    "## and use the () on each condition\n",
    "## 3. I'm breaking up my code into multiple lines for readability with the \\ character\n",
    "nta_2263_merged.loc[(nta_2263_merged['perc_flood']>=0.004067)&\\\n",
    "                    (nta_2263_merged['perc_flood']<=0.016422),'risk_categories'] = 'average'\n",
    "\n",
    "## Always make sure that you're not double counting your rows\n",
    "## If you use a <=X condition, you'll need to use a >X condition\n",
    "nta_2263_merged.loc[nta_2263_merged['perc_flood']>0.016422,'risk_categories'] = 'high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a9b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_2263_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_2263_merged.plot(column='risk_categories', \n",
    "                        legend=True,\n",
    "                        categorical=True,\n",
    "                        figsize=(10,10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97beda13",
   "metadata": {},
   "source": [
    "## Q.3 - Missing data (2 pts)\n",
    "Oops, what happened to those neighborhoods that weren't categorized? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aee1d69f",
   "metadata": {},
   "source": [
    "## Optional: Q.4 - Classifying Data (5 pts)\n",
    "How would you recategorize those empty neighborhoods? Map the re-categorized data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5401ca16",
   "metadata": {},
   "source": [
    "## Q.5 (10pts) - Spatial join\n",
    "- Download the [Points of Interest](https://data.cityofnewyork.us/City-Government/Points-Of-Interest/rxuy-2muj) dataset from the NYC OpenData portal\n",
    "- Download the [NYCHA Developments](https://data.cityofnewyork.us/Housing-Development/Map-of-NYCHA-Developments/i9rv-hdr5) dataset again. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For each NYCHA development, calculate the number of POIs within a 15 minute walkshed. Which development has the most POIs within a 15 minute walkshed? Which development has the least? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:12:38) \n[Clang 11.0.1 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc571d7ca67236538d190807671ab3198970b7d67f23d825ad141ff90f68066a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
