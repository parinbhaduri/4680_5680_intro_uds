{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A note about accessing the course files through Github\n",
    "\n",
    "All of the lectures notes will be posted on the [class Github repo](https://github.com/iamwfx/4680_5680_intro_uds). \n",
    "\n",
    "We are (probably) not going over git and Github during class. If you're familiar with git/Github, feel free to clone the repo to get the new lecture materials for each class. Otherwise, I recommend you do the following: \n",
    "- Create class folder and name it `Intro_UDS`\n",
    "- For each week, create a folder called `Week1`, `Week2`, etc. \n",
    "- To download the materials (Juputer notebook, data files, etc.), navigate to the file you want to download and select `Raw` above the view of the file. \n",
    "- Save this \"raw\" file in your class folder and **make sure it is in the proper file format**. For instance, if the file is `.ipynb` make sure you save the downloaded file as `.ipynb` (your computer might try to default to `.txt`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-tucson",
   "metadata": {},
   "source": [
    "# Learning goals\n",
    "After this week's lesson you should be able to:\n",
    "- Explain what a Pandas Series is and how to select, filter, and replace valuess in the series \n",
    "- Read and explore tabular data in Python using a Pandas DataFrame\n",
    "- Read and write data to a .csv text file\n",
    "\n",
    "This week's lessons are adapted from:\n",
    "- [Geo-Python Lesson 5](https://geo-python-site.readthedocs.io/en/latest/lessons/L5/overview.html)\n",
    "- [Practical Data Science on Pandas Series](https://www.practicaldatascience.org/html/pandas_series.html)\n",
    "- [Practical Data Sciece on Pandas DataFrames](https://www.practicaldatascience.org/html/30_pandas_dataframes.html)\n",
    "\n",
    "# Grading\n",
    "Each exercise will be graded based on the following rubrics:\n",
    "- 5 points. Completed all the tasks and codes were well documented and explained.\n",
    "- 4 points. Completed all the tasks with minor mismatch with the expected results (less than 10%).\n",
    "- 3 points. Completed all the tasks with some mismatch with the expected results (more than 10% but less than 50%).\n",
    "- 2 points. Completed all the tasks with major mismatch with the expected results (over 50%).\n",
    "- 1 point. Made an attempt but didn’t finish any of the exercises.\n",
    "- 0 point. Did not complete the excercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-diana",
   "metadata": {},
   "source": [
    "# 0. What is Pandas? \n",
    "\n",
    "[Pandas](http://pandas.pydata.org/) is a widely used Python library for data analysis. \n",
    "\n",
    "### Easy-to-use data structures\n",
    "In pandas, the data is typically stored in a data structure called a\n",
    "DataFrame that looks like a typical table with rows and columns (+\n",
    "indices and column names), where columns can contain data of different\n",
    "data types. Thus, it is similar in some sense to how data is stored in\n",
    "Excel or in R, which also uses a concept of a dataframe. In fact, Wes\n",
    "McKinney first [developed pandas as an alternative for\n",
    "R](https://blog.quantopian.com/meet-quantopians-newest-advisor-wes-mckinney/)\n",
    "to deal with different complex data structures.\n",
    "\n",
    "### Summary of the pandas data structure\n",
    "The below is a picture of how data is structured in a dataframe. You can see it is tabular structure with rows, columns, and a (row) index, which is in many ways similar to what you might be familiar with from a Excel or Google Spreadsheets. Using this structure, we can apply operations like arithmetic, columns and rows selection, columns and rows addition etc.\n",
    "\n",
    "![Alt text](img/creating_dataframe1.png)\n",
    "\n",
    "### Combines functionalities from many Python modules\n",
    "\n",
    "pandas takes advantage of the [NumPy](http://www.numpy.org/) module\n",
    "under the hood, which is mostly written in C. This makes it a fast and\n",
    "powerful library that can efficiently handle even very large datasets.\n",
    "pandas offers an easier and more intuitive syntax to do data analysis\n",
    "and manipulation using either Numpy functionalities in the background or dedicated functionalities written explicitly for pandas. However, pandas is much more than an easier-to-use Numpy as it also combines many functionalities from other Python libraries such as [matplotlib (plotting)](https://matplotlib.org/) and [scipy(mathematics, science, engineering)](https://www.scipy.org/). Thus, you can use many of the features included in those packages without importing them at all.\n",
    "\n",
    "### Supports data read/write from multiple formats\n",
    "One of the most useful features of pandas is its ability to read data\n",
    "from numerous different data formats directly. For example, pandas\n",
    "supports reading and writing data from/to:\n",
    "\n",
    "-   CSV\n",
    "-   JSON\n",
    "-   HTML\n",
    "-   MS Excel\n",
    "-   HDF5\n",
    "-   Stata\n",
    "-   SAS\n",
    "-   Python Pickle format\n",
    "-   SQL (Postgresql, MySQL, Oracle, MariaDB, etc.)\n",
    "\n",
    "You can view the full list of supported data formats from the [pandas\n",
    "docs](https://pandas.pydata.org/docs/user_guide/io.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-tiffany",
   "metadata": {},
   "source": [
    "# 1. Pandas Series\n",
    "The building block of Pandas dataframes are Pandas **Series**. A Series is an ordered list of values, generally all of the same type. If you're familiar with Numpy arrays, a Series is a just a one-dimensional Numpy array with some added features. \n",
    "\n",
    "There are lots of ways to create Series, but the easiest is to just pass a list or an array to the pd.Series constructor.\n",
    "\n",
    "Let's create a series for the [top 5 metropolitan statistical areas in the U.S. by population according to 2021 estimates](https://en.wikipedia.org/wiki/Metropolitan_statistical_area). \n",
    "\n",
    "1. New York-Newark-Jersey City, NY-NJ-CT-PA MSA (19,768,458)\n",
    "2. Los Angeles-Long Beach-Anaheim, CA MSA (12,997,353)\n",
    "3. Chicago-Naperville-Elgin, IL-IN-WI MSA (9,509,934)\n",
    "4. Dallas-Fort Worth-Arlington, TX MSA (7,759,615)\n",
    "5. Houston-The Woodlands-Sugar Land, TX MSA (7,206,841)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's first import the pandas library\n",
    "### We will use the alias pd for pandas to make it easier to type. \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's create a pandas series from a list\n",
    "population = pd.Series([19768458, 12997353, 9509934, 7759615, 7206841])\n",
    "population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-chambers",
   "metadata": {},
   "source": [
    "## 1.1 Indices\n",
    "Somewhat different from a standard list or array, we can include an index value associated with each row from this series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's create a pandas series from a list that has an index\n",
    "population = pd.Series([19768458, 12997353, 9509934, 7759615, 7206841],    \n",
    "            index=['NYC', 'LA', 'Chicago', 'Dallas', 'Houston'])\n",
    "population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-houston",
   "metadata": {},
   "source": [
    "Now, you can see that there are index values associated with each population count. You can access a Series’ index with the `.index` property: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-quantum",
   "metadata": {},
   "source": [
    "Different than working with tabular data in a spreadsheet software, the indicies stay with each row. So, say you wanted to sort your values from smallest to largest, like so, the row indices will be sorted as well to stay with the row values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-fault",
   "metadata": {},
   "source": [
    "## 1.2 Subsetting a Series\n",
    "Very often, we will want to subset or filter our series based on certain criteria like the position or range of values, or [logicals](https://www.geeksforgeeks.org/python-logical-operators-with-examples-improvement-needed/) such as whether values are bigger/smaller than a certain number. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-canvas",
   "metadata": {},
   "source": [
    "### 1.2.1 `.iloc`\n",
    "In order to select the row(s) based on their position in the table, we use the `.iloc` function. For instance, if I want to select the first row value in my `population` Series, I can type: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-front",
   "metadata": {},
   "source": [
    "Note: In Python, we start our count at 0. So 0 = first, 1 = second, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-boxing",
   "metadata": {},
   "source": [
    "If I wanted to select the first three row value I can use the `:` to select a range of values `0:3`. \n",
    "\n",
    "Be careful, using **integer ranges excludes the last value in the range**. So, `0:3` gives us the first **three** values even though you might think you're selecting up to the fourth row value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-antarctica",
   "metadata": {},
   "source": [
    "### 1.2.2 `.loc`\n",
    "You can also select a range of rows by the index values using the function `.loc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.loc['NYC']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-reunion",
   "metadata": {},
   "source": [
    "And in the same way, we can also select ranges. Using index label ranges, this **includes** the last value of the range: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.loc['NYC':'Chicago']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-therapist",
   "metadata": {},
   "source": [
    "### 1.2.3 Subsetting based on logicals\n",
    "Another criteria we can use is a logical condition for which each row value will return a Boolean, either `True` or `False`. \n",
    "\n",
    "Say I wanted to find all the cities in my population series that have poplations larger than 8 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_than_8m = population > 8000000\n",
    "larger_than_8m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-vegetarian",
   "metadata": {},
   "source": [
    "The top three MSAs have all returned `True` while Dallas and Houston MSAs, which have populations under 8 million return `False`.\n",
    "\n",
    "We can apply this condition to our series to get the subset of the series that a `True` condition for the logical we've described: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.loc[larger_than_8m]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-specialist",
   "metadata": {},
   "source": [
    "### 1.2.4 The Single Square Brackets `([])` \n",
    "There is yet another way to subset and filter data by simply adding brackets after your dataframe. It is pandas' way of simplifying subsetting and filtering.\n",
    "\n",
    "If you want to select based on the index value, the following will work: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "population['Chicago']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-antigua",
   "metadata": {},
   "source": [
    "You can also pass a logical: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "population[population>8000000]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-algebra",
   "metadata": {},
   "source": [
    "However, if your index is not integer-based, the square brackets will work like `.iloc`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "population[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-wrestling",
   "metadata": {},
   "source": [
    "### 1.2.5 Types of Series\n",
    "The each series can be composed of different series types:\n",
    "- Numbers, either integers (`int64` or `int32`) or floats `float64` or `float32`)\n",
    "- Strings (`str`), i.e. text\n",
    "- Objects (`O`), which is a flexible category that can hold either numbers, strings, or a mix. \n",
    "\n",
    "Note: the 32 or 64 after `int` and `float` refer to how many bits are allocated for each type. If we have a series that is `int64`, then each value in the series can go up to 64 digits. \n",
    "\n",
    "So if we type the following, we can see that our Series is an `int64`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-robinson",
   "metadata": {},
   "source": [
    "Let's check the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3.14])\n",
    "s.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, \"a string\"])\n",
    "s.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-comedy",
   "metadata": {},
   "source": [
    "#### 1.2.4.1 Converting data types\n",
    "Every once in a while, we'll have to change datatypes. You can do this using the `.astype()` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3])\n",
    "s = s.astype('float64')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-signature",
   "metadata": {},
   "source": [
    "But if you try to convert an “object” Series to a “numeric” Series and there are numbers that can’t be converted, pandas will throw an error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, \"a string\"])\n",
    "s.astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-fossil",
   "metadata": {},
   "source": [
    "## 1.3 Series Arithmetics\n",
    "There are three forms of Series arithmetic:\n",
    "\n",
    "- A Series with more than one element and a Series with only one element.\n",
    "- A Series modified by a function.\n",
    "- Two Series with the same number of elements. When working with two Series, elements are matched based on index values, not row numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "population*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10000,2000020,30003000,40040000,50000005],\n",
    "            index=['NYC', 'LA', 'Chicago', 'Dallas', 'Houston'])\n",
    "\n",
    "population+s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-delta",
   "metadata": {},
   "source": [
    "## 1.4 Modifying series elements\n",
    "Essentially, in the same way that we can select row elements we can also update them using the same logic. \n",
    "\n",
    "Say we needed to update the LA metro area in our `population` series (I'll just make up a fake population update for now) from `12997353` to `15000000`. \n",
    "\n",
    "There are a few ways to do this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter for population value\n",
    "population[population==12997353] = 15000000\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the .loc method\n",
    "population.loc['LA'] = 15000000\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the .iloc method\n",
    "population.iloc[1] = 15000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the square bracket method\n",
    "### (Let's reset the population series to the original values for demo purposes)\n",
    "population = pd.Series([19768458, 12997353, 9509934, 7759615, 7206841],    \n",
    "            index=['NYC', 'LA', 'Chicago', 'Dallas', 'Houston'])\n",
    "\n",
    "population['LA'] = 15000000\n",
    "## or \n",
    "population[1] = 15000000\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-cathedral",
   "metadata": {},
   "source": [
    "# 2. DataFrames\n",
    "Pandas DataFrames are tabular data consisting of a collection of Series in which each column is a series. It is the central data structure used in most analysis using the Pandas library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msa_by_pop = pd.read_html(\"https://en.wikipedia.org/wiki/Metropolitan_statistical_area\",encoding=\"latin-1\",)[1]\n",
    "# msa_by_pop.columns = ['Rank', 'MSA', 'population_2021_est', 'population_2020',\n",
    "#        'perc_change', 'Encompassing combined statistical area']\n",
    "# msa_by_pop['perc_change'].replace('â','',regex=True,inplace=True)\n",
    "# msa_by_pop[['Rank','MSA','population_2021_est','population_2020','perc_change']].to_csv('msa_by_pop.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-lemon",
   "metadata": {},
   "source": [
    "First, let's read in our data using the pandas function `.read_csv()`. \n",
    "\n",
    "One of the nifty things about reading data in pandas is that it's designed to read many different types data sources, from files, to QL databases, and URLs. Here are a few to know about: \n",
    "- `pd.read_csv`: Read in a comma-separated-value file\n",
    "- `pd.read_excel`: Read in an Excel (`.xls` and `.xlsx`) spreadsheet\n",
    "- `pd.read_stata`: Read Stata (`.dta`) datasets\n",
    "- `pd.read_hdf`: Read HDF (`.hdf`) datasets\n",
    "- `pd.read_sql`: Read from a SQL database\n",
    "- `pd.read_html`: Read from the `html` tags of an HTML file\n",
    "\n",
    "Similarly, you can write a dataframe to many formats: (`df` here is the name of a dataframe)\n",
    "- `df.to_csv`: Write to a comma-separated-value file\n",
    "- `df.to_excel`: Write to an Excel (.xls and .xlsx) spreadsheet\n",
    "- `df.to_stata`: Write to a stata (.dta) dataset\n",
    "- `df.to_hdf`: Write to an HDF (.hdf) dataset\n",
    "- `df.to_sql`: Write to a SQL database\n",
    "- `df.to_html`: Write to an HTML table. \n",
    "\n",
    "\n",
    "Check out the [Pandas documentation on input/output](https://pandas.pydata.org/docs/reference/io.html) to see all the possible functions for reading data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-monte",
   "metadata": {},
   "source": [
    "## 2.1 Reading a file\n",
    "Download the `msa_by_pop.csv` in this week's folder. We are first going to read this CSV as DataFrame into Pandas.\n",
    "\n",
    "The function `.read_csv()` takes a file path as a string (read: text). If you have saved `msa_by_pop.csv` in the same folder as this notebook, then all you will need to input as your path is `msa_by_pop.csv`. \n",
    "\n",
    "(If you had saved your CSV within a sub-directory called `Data`, then to access this data file you'd need to input `Data/msa_by_pop.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop = pd.read_csv('msa_by_pop.csv')\n",
    "msa_by_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-tactics",
   "metadata": {},
   "source": [
    "## 2.2 Exploring our data\n",
    "You can see here that (in addition to the formatting of tabular data in Jupyter) the main difference between this and a series is that we have multiple columns with column labels. So the dataframe structure consists of: \n",
    "- An index, with index labels (here the labels are just `0`,`1`,...,`383`)\n",
    "- Columns, with column labels (here `MSA`, `population_2021_est`, `population_2020`,`perc_change`)\n",
    "- And the data, which are the values in each row. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-affect",
   "metadata": {},
   "source": [
    "Now, in addition to `.index` we can also see all the columns in our DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-rachel",
   "metadata": {},
   "source": [
    "Now, to see the datatypes for each column, we use `.dtypes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-juvenile",
   "metadata": {},
   "source": [
    "One common function used to explore the data is called `.head()` that reveals the first 5 rows of the Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-blackjack",
   "metadata": {},
   "source": [
    "If you start to type `msa_by_pop.head(` without finishing the parens you can see the inputs required of the function: \n",
    "\n",
    "\n",
    "<img src=\"img/func_arg.png\" alt=\"drawing\" width=\"400\" style=\"display: block; margin: 0 auto\"/>\n",
    "\n",
    "\n",
    "This shows us that that `.head()` by default show 5 rows, but you can also optionally adjust this by specifying another integer. For instance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This gives us the first 10 rows\n",
    "msa_by_pop.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-companion",
   "metadata": {},
   "source": [
    "`.sample()` gives us a random selection of rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-cornell",
   "metadata": {},
   "source": [
    "The function `.len()` measures the length of a selection. Applying this to the DataFrame gives you the number of rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(msa_by_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-ancient",
   "metadata": {},
   "source": [
    "Applying it to the columns gives us the number of columns we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(msa_by_pop.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-shopping",
   "metadata": {},
   "source": [
    "The function `.shape` gives us the number of `(rows,columns)` in our dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-child",
   "metadata": {},
   "source": [
    "`.describe()` provides some basic descriptive statistics for our dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-charity",
   "metadata": {},
   "source": [
    "`.sort-values()` sorts your DataFrame by a certain column. If you column is numeric, it will sort the values from smallest to largest. If your column is a string, it will sort alphabetically.\n",
    "\n",
    "The index values will be sorted along with the rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sorts the dataframe by the population_2021_est column, from smallest to largest\n",
    "# Note that the original dataframe is not changed \n",
    "# but that the index values now reflect the sorted order. \n",
    "msa_by_pop.sort_values('population_2021_est')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-connection",
   "metadata": {},
   "source": [
    "Adding the `ascending=False` input in your function will sort from largest to smallest or end of alphabet to beginning, depending on your column data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.sort_values('population_2021_est',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-blues",
   "metadata": {},
   "source": [
    "## 2.3 Subsetting and filtering Dataframes\n",
    "Selecting data from our Dataframes is very similar to a Pandas Series, except now we have two dimensions (rows and columns) for which we have to specify conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-taiwan",
   "metadata": {},
   "source": [
    "For `.iloc` we can select rows and columns now by their position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember integer ranges are exclusive of the last value!\n",
    "msa_by_pop.iloc[0:5,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-keeping",
   "metadata": {},
   "source": [
    "Similarly, using `.loc` we can select rows and columns by their names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our rows are index by integers, when we can use the .loc method to select rows, \n",
    "# it's the same as .iloc\n",
    "msa_by_pop.loc[0:5,['Rank','MSA','population_2021_est']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-belgium",
   "metadata": {},
   "source": [
    "You can always leave out the column argument in either `.loc` or `.iloc` in order to select all columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.loc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-regard",
   "metadata": {},
   "source": [
    "But to do the same with columns you'll first have to specify that you want all the rows with `:` . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.loc[:,['Rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.iloc[:,[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-roots",
   "metadata": {},
   "source": [
    "With the square brackets `[]` you can provide a list of columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop[['Rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop[['Rank','population_2020']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-plaza",
   "metadata": {},
   "source": [
    "We can again filter by logicals, but you'll need to specify the column names now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.loc[msa_by_pop['Rank']>300]\n",
    "# Yes, msa_by_pop['Rank'] does also select the column, \n",
    "# but notice that it gives a Series instead of a dataframe one column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-storm",
   "metadata": {},
   "source": [
    "In order to filter by more than one condition, you must: \n",
    "1. Put all conditions in `()`\n",
    "2. Separate the condtions by: \n",
    "\n",
    "    a. `|` if an `OR` condition     \n",
    "    b. `&` if an `AND` condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop[(msa_by_pop['Rank']>300) & (msa_by_pop['MSA'].str.contains('NY'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop[(msa_by_pop['Rank']>300) | (msa_by_pop['MSA'].str.contains('NY'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-pattern",
   "metadata": {},
   "source": [
    "# 3. Good Coding Practices\n",
    "\n",
    "The following are some good practices for writing more legible Jupyter notebooks. Often, we don't necessarily realize that code we write isn't immediately interpretable to readers. To make code more easily interpreted, we will often explain through markdown text or comments what we are doing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-gross",
   "metadata": {},
   "source": [
    "## 3.1 Markdown and explanatory cells\n",
    "As you can see in this notebook, there are many \"Markdown\" cells surrounding our actual code. The markdown I have here describes the purpose of each code cell and what I wanted to do with it. \n",
    "\n",
    "I often organize my notebooks by header size `#`, `##` etc, and by numbering the different sections. This can be helpful if you're writing an especially long notebook. \n",
    "\n",
    "Here's a [guide on how to write in Markdown](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-grain",
   "metadata": {},
   "source": [
    "## 3.2 Formatting code\n",
    "Sometimes, code can be very long. For instance, your function might have a bunch of inputs or you have many conditionals.\n",
    "\n",
    "Depending on how wide your browser window is, this code may not fit in the window: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop[(msa_by_pop['Rank']>300) & (msa_by_pop['MSA'].str.contains('NY')) & (msa_by_pop['population_2020']>100000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-fossil",
   "metadata": {},
   "source": [
    "Instead, we can use `\\` to start a new line. The below is also clearer because each condition is its own line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop[(msa_by_pop['Rank']>300) &\\\n",
    "        (msa_by_pop['MSA'].str.contains('NY')) &\\\n",
    "        (msa_by_pop['population_2020']>100000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-quest",
   "metadata": {},
   "source": [
    "You can also use the `#` in a code cell to comment. You can see that sometimes I have small notes in there that maybe didn't need to go into the markdown cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code comment\n",
    "msa_by_pop[(msa_by_pop['Rank']>300) &\\\n",
    "        (msa_by_pop['MSA'].str.contains('NY')) &\\\n",
    "        (msa_by_pop['population_2020']>100000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-berry",
   "metadata": {},
   "source": [
    "## 3.3 Selecting variable names\n",
    "There are two aspects of select variable names we're going to go over today: \n",
    "1. What to name your variables or function\n",
    "2. How to name a multi-word variable or function\n",
    "\n",
    "### 3.3.1\n",
    "A good variable name should: \n",
    "- Be clear and concise.\n",
    "- Be written in English. A general coding practice is to write code with variable names in English, as that is the most likely common language between programmers. Thus, variable names such as muuttuja (which is also not a good name on other levels) should be avoided.\n",
    "- Not contain special characters. Python supports use of special characters by way of various encoding options that can be given in a program. That said, it is better to avoid variables such as lämpötila because encoding issues can arise in some cases. Better to stick to the standard printable ASCII character set to be safe.\n",
    "- Not conflict with any Python keywords, such as for, True, False, and, if, or else. These are reserved for special operations in Python and cannot be used as variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not do this: \n",
    "finnishmeteorlogicalinstituteobservationstationidentificationnumber = \"101533\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or this: \n",
    "f = \"101533\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something that is as short as possible while still being descriptive is best\n",
    "sid = \"101533\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-checklist",
   "metadata": {},
   "source": [
    "### 3.3.2 Snake case and camel case\n",
    "There are two general ways of connecting variable and function names that contain more than one word. \n",
    "\n",
    "You can see from the above exercise that I've named my DataFrame `msa_by_pop`. Connecting words by `_`  is called \"Snake Case\". \n",
    "\n",
    "Another convention is to use capital letters to start new words. `msaByPop` could be another way to name our variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-sperm",
   "metadata": {},
   "source": [
    "# 4. In-Class Exercises\n",
    "Each week, we will have in-class exercises that give you some pratice on the concepts learned in class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-welding",
   "metadata": {},
   "source": [
    "## 4.1. Exercise 1 (5 points)\n",
    "For this exercise, we are going to use the table from the earlier examples. Instead of reading the table from a CSV, let's read the table directly from the [Wikipedia page on Metropolitan Statistical Areas](https://en.wikipedia.org/wiki/Metropolitan_statistical_area)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "msa_by_pop = pd.read_html(\"https://en.wikipedia.org/wiki/Metropolitan_statistical_area\")[1]\n",
    "msa_by_pop.columns =['Rank', 'MSA', 'population_2021_est', 'population_2020',\n",
    "       'perc_change', 'Encompassing_combined_statistical_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-curve",
   "metadata": {},
   "source": [
    "Which is the MSA with the 10th largest population as estimated for 2021? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-dispute",
   "metadata": {},
   "source": [
    "Select the smallest 10 MSAs by 2020 Census population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-boulder",
   "metadata": {},
   "source": [
    "Find the total 2020 Census population of these 384 MSAs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-egyptian",
   "metadata": {},
   "source": [
    "Based on the population growth between 2020 and 2021, let's estimate the population in 2021 using the following function: \n",
    "\n",
    "$$\n",
    "pop_{year2} =pop_{year1}*(1+ {\\% change})^t\n",
    "$$\n",
    "\n",
    "where $t=1$ here and $\\% change$ is the percentage estimated change in population from 2020.\n",
    "\n",
    "First, calculate the percentage change between 2020 and 2021 and create a new column with these values called `year_change`. Do not multiply by 100, just keep the values in their original decimal form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here\n",
    "msa_by_pop['year_change'] = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-desire",
   "metadata": {},
   "source": [
    "Does `year_change` line up with the `% change` column that we already have? Select the two columns together to do an eyeball estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-triangle",
   "metadata": {},
   "source": [
    "Now using your new `year_change` column, created another column called `population_2021_estimate` and estimate the 2021 population counts using the formula above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here\n",
    "msa_by_pop['population_2021_estimate']= \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-officer",
   "metadata": {},
   "source": [
    "## 4.2 Exercise 2 (5 points)\n",
    "In this exercise, we are going to explore urban population change over the previous decade. \n",
    "\n",
    "Here, we are going to read the Excel file on \"Annual Estimates of the Resident Population: April 1, 2010 to July 1, 2019\" directly from the [U.S. Census Bureau's website](https://www.census.gov/data/tables/time-series/demo/popest/2010s-total-metro-and-micro-statistical-areas.html).\n",
    "\n",
    "Below, I'm going to do some data cleaning and re-formatting so the table is easier to work with.\n",
    "\n",
    "Each column with the year is the Census estimated MSA population for that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .read_excel() reads an Excel spreadsheet from a local file or from a URL. \n",
    "# Most .read_*() methods can read from both local files and URLs.\n",
    "# The default sheet is the first one, but you can specify a different sheet by name or index.\n",
    "\n",
    "# skiprows=3 skips the first 3 rows, header=0 uses the first row as column names\n",
    "msa_pop_2010_2019 = pd.read_excel('https://www2.census.gov/programs-surveys/popest/tables/2010-2019/metro/totals/cbsa-met-est2019-annres.xlsx',\n",
    "                                skiprows=3,header=0) \n",
    "\n",
    "# Because this is an Excel file with multiple header-type rows, \n",
    "# we need to skip the first 3 rows\n",
    "msa_pop_2010_2019 = msa_pop_2010_2019.iloc[2:]\n",
    "\n",
    "# I'm going to rename the columns to make them easier to work with\n",
    "msa_pop_2010_2019.columns = ['MSA','apr_1_2010','Estimates Base','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\n",
    "\n",
    "# And I'm selecting only the columns we need for this exercise\n",
    "msa_pop_2010_2019 = msa_pop_2010_2019[['MSA','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']]\n",
    "\n",
    "# And I'm going to remove the rows that are not Metropolitan Statistical Areas \n",
    "# by filtering on the string 'Metro Area'\n",
    "msa_pop_2010_2019 = msa_pop_2010_2019[msa_pop_2010_2019['MSA'].str.contains('Metro Area')]\n",
    "\n",
    "# There's strangely a period at the beginning of each MSA name, so I'm going to remove it\n",
    "msa_pop_2010_2019['MSA'] = msa_pop_2010_2019['MSA'].str.replace('.','')\n",
    "\n",
    "# And I'm going to remove the word 'Metro Area' from the end of each MSA name\n",
    "msa_pop_2010_2019['MSA'] = msa_pop_2010_2019['MSA'].str.replace(' Metro Area','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-episode",
   "metadata": {},
   "source": [
    "Let's take a look at the first 5 rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-anatomy",
   "metadata": {},
   "source": [
    "Now, create a new column that represents the percentage change in population between 2010 and 2019 and call this column `perc_pop_change`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here\n",
    "\n",
    "msa_pop_2010_2019['perc_pop_change'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-youth",
   "metadata": {},
   "source": [
    "Print the average population change for the 10 **largest** MSAs by population in 2010. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "# change_top_10 = \n",
    "\n",
    "\n",
    "# The print function is used to print a string to the screen\n",
    "print('The average population change for the 10 largest MSAs between 2010 and 2019 is', \n",
    "        round(change_top_10*100,4),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-playlist",
   "metadata": {},
   "source": [
    "Now print the average population change for the 10 **smallest** MSAs by population in 2010. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "# change_bottom_10 = \n",
    "\n",
    "print('The average population change for the 10 smallest MSAs between 2010 and 2019 is', \n",
    "    round(change_bottom_10*100,4),'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc571d7ca67236538d190807671ab3198970b7d67f23d825ad141ff90f68066a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
